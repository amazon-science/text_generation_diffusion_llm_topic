{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d6f63d-ebcf-4000-b456-d5fb2a041deb",
   "metadata": {},
   "source": [
    "# this notebook is used to generate the vectors based on the diffusor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb39f28-e053-44d3-846a-94991602947b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenxiahu/anaconda3/envs/sum-finetune/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workplace/wenxiahu/Vontss/example/../src/topicmodeling/CNN_Encoder.py:15: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric('sacrebleu')\n",
      "Fabric will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Fabric(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, Dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "from transformers import PretrainedConfig\n",
    "from typing import List\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSeq2SeqLM, LEDForConditionalGeneration\n",
    "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType, PeftModel, PeftModelForSeq2SeqLM, PeftConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src/')\n",
    "# sys.path.append('../mlti_document_summarization/')\n",
    "# sys.path.append('../mlti_document_summarization/experiment_scripts/')\n",
    "\n",
    "# from utils import *\n",
    "# from data_process import *\n",
    "import topicmodeling.flanT5_cnn_lighting as fcl\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import boto3\n",
    "import gc\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#{'translation': {'en': text, 'fr': text}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354c027-685b-406d-96f7-5bc2481a430f",
   "metadata": {},
   "source": [
    "## defusion in the embedding space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183c273-f3fe-49a6-a35e-3d1bf8bcb6fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### loading our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98656c2-4d5c-4abe-9538-eb9f110a7ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# args.test_dataset_local_prefix = '/home/wenxiahu/WXWH/long_docs/long_xsum_evaluate_data/1207_t20_1111'\n",
    "\n",
    "args.finetune_tokenizer_name = 'google/flan-t5-large'\n",
    "args.finetune_model_name = 'google/flan-t5-large'\n",
    "\n",
    "args.hidden_size1 = 512\n",
    "args.max_length = 512\n",
    "\n",
    "args.device = 'cuda:7'\n",
    "\n",
    "args.finetune_artifact_local_prefix = '/home/wenxiahu/WXWH/pretrain_reconstruct/model_0122/'\n",
    "args.finetune_artifact_model_file_name = 'flant5_nest_peftflan-t5-large8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b43b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = PeftConfig.from_pretrained(args.finetune_artifact_local_prefix)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "# model = PeftModel.from_pretrained(model, args.finetune_artifact_local_prefix)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# t5autoConfig = T5AutoConfig(\n",
    "#         hidden_size3=4,\n",
    "#         model = 'CNN')\n",
    "# models = FlanT5NestCNNAutoencoder(t5autoConfig).to(args.device)\n",
    "# print('load', args.finetune_artifact_local_prefix + '/' + args.finetune_artifact_model_file_name)\n",
    "# logging.info('load ' + args.finetune_artifact_local_prefix + '/' + args.finetune_artifact_model_file_name)\n",
    "# models.load_state_dict(torch.load(args.finetune_artifact_local_prefix + '/' + args.finetune_artifact_model_file_name))\n",
    "# models.model = model.to(args.device)\n",
    "# models.encoder = models.encoder.to(args.device)\n",
    "# models.decoder = models.decoder.to(args.device)\n",
    "\n",
    "# models.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb594c9a-a55a-4491-b5ec-9c95538c89d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load /home/wenxiahu/WXWH/pretrain_reconstruct/model_0122//flant5_nest_peftflan-t5-large8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlanT5NestCNNAutoencoder(\n",
       "  (model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 1024)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 1024)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 16)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-23): 23 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 1024)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 16)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-23): 23 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       "  )\n",
       "  (encoder): CNNEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(128, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (3): ReLU()\n",
       "      (4): Conv1d(16, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       "  (decoder): CNNDecoder(\n",
       "    (decoder): Sequential(\n",
       "      (0): Conv1d(4, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(16, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (3): ReLU()\n",
       "      (4): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.finetune_tokenizer_name)\n",
    "\n",
    "config = fcl.T5AutoConfig(hidden_size1=args.hidden_size1, hidden_size3=4, \n",
    "                hidden_size2=768, output_size=4 * 768, \n",
    "                # model = 'CNN',\n",
    "                model=args.finetune_model_name,\n",
    "                )  # Replace with your config\n",
    "models = fcl.FlanT5NestCNNAutoencoder(config)\n",
    "\n",
    "print('load', args.finetune_artifact_local_prefix + '/' + args.finetune_artifact_model_file_name)\n",
    "# logging.info('load ' + args.finetune_artifact_local_prefix + '/' + args.finetune_artifact_model_file_name)\n",
    "models.load_state_dict(torch.load(args.finetune_artifact_local_prefix + '/' + args.finetune_artifact_model_file_name, map_location='cpu'))\n",
    "\n",
    "models.model = models.model.to(args.device)\n",
    "models.encoder = models.encoder.to(args.device)\n",
    "# models.decoder = models.decoder.to(args.device)\n",
    "\n",
    "models.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac770f5c",
   "metadata": {},
   "source": [
    "### sampling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1df5ed-d3f8-4e9c-bb00-3350a7f7a25c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_name = 'whu9/xsum_postprocess'\n",
    "# dataset = load_dataset(dataset_name)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f77d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset = load_dataset(dataset_name)\n",
    "\n",
    "# dataset = dataset['train'].select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2fdd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_sample_path = \"/home/wenxiahu/WXWH/diffusion/data/data_sample_10000\"\n",
    "# os.makedirs(dataset_sample_path, exist_ok=True)\n",
    "# dataset.save_to_disk(dataset_sample_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e2108",
   "metadata": {},
   "source": [
    "### generate the embedding using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "881403d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"/home/wenxiahu/WXWH/diffusion/data/data_sample_1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc39cdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'summary', 'source_num_tokens', 'summary_num_tokens'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650ea2ae-8df6-4f18-b5d1-1ec78fe1f5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['source', 'summary', 'source_num_tokens', 'summary_num_tokens'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [02:18<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "text_ls = dataset['summary']\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "batch_ls = [text_ls[ind: ind + batch_size]for ind in range(0, len(text_ls), batch_size)]\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "for text in tqdm(batch_ls):\n",
    "\n",
    "    # inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    # attention = tokenizer(text, return_tensors=\"pt\").attention_mask\n",
    "\n",
    "    # add instruction\n",
    "    # text = ['repeat: ' + t for t in text]\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length = args.max_length)\n",
    "    \n",
    "    # get the inputs and attention\n",
    "    inputs_id = inputs.input_ids.to(models.device)\n",
    "    attention = inputs.attention_mask.to(models.device)\n",
    "    \n",
    "    output = models.model.encoder(inputs_id, attention).last_hidden_state   #batch size * seq length * embedding size, \n",
    "    output = models.encoder(output)\n",
    "    outputs.append(output.detach().cpu())\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd65ab2e-542b-438b-8b99-51d8a6a067b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4, 1024])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(outputs, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace7d995-8a51-4e8d-8740-90905ac928a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embedding\n",
    "torch.save(torch.cat(outputs, dim=0), f'./embed_vectors_base_7_1000_prefix.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46bd2b",
   "metadata": {},
   "source": [
    "### train a diffusor using at the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc04a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in terminal\n",
    "# python ./src/diffusion/diffuser_training.py --embedding_input './example/embed_vectors_base_7_1000_prefix.pt' --model_name 'UNet_Conv' --output_dir './example'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639f48a-9e50-4809-995b-077de7be4973",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3872d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.diffuser_training import UNetConv, DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baa0da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_embeddings = torch.cat(outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbd61196-9368-44b0-87de-585c904c3bad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetConv(\n",
       "  (embedding): SinusoidalPositionEmbeddings()\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv1d(4, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): ConvTranspose1d(1024, 512, kernel_size=(2,), stride=(2,))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): ConvTranspose1d(512, 256, kernel_size=(2,), stride=(2,))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv1d(64, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim=4 * 1024\n",
    "num_images=5\n",
    "device = 'cuda:6'\n",
    "\n",
    "x = generated_embeddings[:num_images]\n",
    "\n",
    "model = UNetConv(generated_embeddings.shape[2], generated_embeddings.shape[1], generated_embeddings.shape[1])\n",
    "model.load_state_dict(torch.load('./diffusion_model.pt'))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00db9ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4, 1024]), device(type='cpu'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b4082-b448-465b-822f-0711d9068aca",
   "metadata": {},
   "source": [
    "### examples: check what sentences we generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ef398",
   "metadata": {},
   "source": [
    "##### denoise from the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c09a0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.diffusion_generate import generate_diffused_embed, generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0643f481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 'cuda:6')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6825b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling :: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:06<00:00, 152.83it/s]\n",
      "Sampling :: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:06<00:00, 164.37it/s]\n",
      "Sampling :: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:05<00:00, 168.42it/s]\n",
      "Sampling :: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:06<00:00, 163.70it/s]\n",
      "Sampling :: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:06<00:00, 164.32it/s]\n",
      "Sampling :: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:05<00:00, 169.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate from the noise vector\n",
    "sampling_turn = 2\n",
    "timesteps = 1000\n",
    "\n",
    "x_noise = torch.randn((num_images, 4, latent_dim // 4), device=device)\n",
    "x_track_ls_ls_noise, x_0_track_ls_ls_noise = generate_diffused_embed(x_noise, model, timesteps, device, batch_size=2, \n",
    "                            num_generated_sample=2, return_all_time_embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d1c694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'The US election is being re-elected as a whole by the Labour Party. ',\n",
       " 'In the US, there are no clear rules on which films can be used. ',\n",
       " 'In the last couple of weeks, I have been asked by a number of friends to tell me about the history of the Japanese shit. ',\n",
       " 'In the US, all the races are civil, except for the one where the commutation is prohibited.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before denoise\n",
    "x = x_track_ls_ls_noise[0][0]\n",
    "text_1 = generate_text(x, models, tokenizer, max_length=512, sub_batch=6, device=args.device)\n",
    "text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b17b5b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The United States Postal Service has announced that it will close its offices in the next nine days to allow for the return of its fugitives.',\n",
       " 'The US election is about to begin. The candidates, who have chosen not to vote, are :',\n",
       " \"In the course of history, there are no clear winners. But the idea that someone can be a  nuisance '' is being explored by the government.\",\n",
       " \"The US election is about to begin. Here's a list of candidates who have participated in it. \",\n",
       " 'The US election is a mess. But it is getting better. ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after denoise\n",
    "x = x_track_ls_ls_noise[0][-1]\n",
    "text_1 = generate_text(x, models, tokenizer, max_length=512, sub_batch=6, device=args.device)\n",
    "text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fc47910-2358-41bf-9ea5-80a00f535445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The CIA has a new weapon in its bid to retake the throne of London. ',\n",
       " 'The US election is being re-elected as a whole by the British parliamentary party, which has a history of more than two decades.',\n",
       " 'In the US, there are no clear rules on which games can be played. ',\n",
       " 'In the US, there are no clear rules on how long a person can be employed. ',\n",
       " 'In the US, all the races are civil, except for the one where the ball is being tased by a woman.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(x_noise, models, tokenizer, max_length=512, sub_batch=6, device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59249ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "sum-finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
